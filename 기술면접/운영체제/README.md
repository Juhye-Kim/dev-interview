### **Operating System**

1.  컴파일러, 인터프리터

    - 컴파일러, 인터프리터의 차이점

      > 둘 다 고수준언어 → 기계어로 변환하는데, 변환과정이 다르다.

      - 컴파일러 : 런타임 전에 전체코드를 쭉 해석하고 실행을 시작
      - 인터프리터 : 코드를 런타임에 한줄씩, 실시간으로 해석하고 바로 실행
        컴파일러는 전체를 한번에 번역하기 때문에 번역속도는 느리지만, 한번 번역을 마치면 더이상 번역없이 실행만 하면 되기 때문에 실행속도는 더 빠르다.
        인터프리터는 한줄 번역하고 실행하고, 한줄 번역하고 바로실행하고 .. 이렇게 되기 때문에 번역 속도는 빨라도 실행속도는 더 느리다.

    - 스크립트 언어, 컴파일 언어를 나열하고 차이점을 설명하세요
      - 스크립트 언어 : js, python, ruby, PHP...
        - 인터프리터
        - 컴파일 단계없이, 실행단계에서 한줄씩 기계어로 번역 후 실행됨 → 느림
        - 전체 코드에 대한 최적화 어려움
      - 컴파일 언어 : C, C++, Java ...
        - 컴파일러를 통해 사전에 컴파일됨
        - 기계어 상태로 실행됨 → 실행이 빠름
        - 컴파일 단계에서 전체 코드를 기계어로 변환될 때 최적화도 진행해서 실행을 보다 빠르게 할 수 있음

1.  프로그램(Program)이란?

    > 운영체제 위에서 실행 가능한 파일들 (ex. 웹 브라우저, 카톡, 줌 ...), 지시의 모음

1.  프로세스(Process)

    - 프로세스란?
      > 운영체제 위에서 실행 중인 프로그램
          - 프로그램 명령어, 데이터들이 메모리에 올라오고, 실행/대기중인 상태
    - 프로세스끼리 통신하는 방법?
      - IPC (Inter-Process Communication)
        - 프로세스들은 커널이 제공하는 IPC 설비를 이용해 통신
        1. 익명 PIPE
           - 파이프로 두 프로세스를 연결
             - 부모-자식 프로세스처럼 관계를 아는 경우 사용
           - 반이중 통신 (한 쪽은 쓰기만, 한 쪽은 읽기만 가능)
           - 장점 : 사용하기 간단, 데이터 흐름이 단순하면 효율적
           - 단점 : 양방향 통신 구현은 복잡 (파이프 두개 필요)
        1. 이름있는 PIPE
           - 반이중 통신 (익명 파이프랑 비슷) + 이름있는 파일 사용
             - 전혀 모르는 관계의 프로세스 간 통신에 사용
        1. Message Queue
           - 메시지 큐에 메시지를 저장하는 방법
           - 입출력 방식은 이름있는 PIPE와 동일
             - 파이프 = 데이터 흐름
             - 메시지 큐 = 메모리 공간
           - 데이터에 번호를 붙임 → 여러 프로세스가 동시 사용 가능
             - 뮤텍스, 세마포어 같은 동기화가 필요!
        1. 공유 메모리
           - 메모리 영역을 공유하는 방식
             - 파이프, 메세지 큐 = 통신을 이용한 설비
             - 공유 메모리 = 데이터 자체를 공유하도록 지원하는 설비
           - 프로세스가 공유 메모리 할당을 커널에 요청하면, 커널은 해당 프로세스에 다른 프로세스들이 접근 가능한 메모리 공간을 할당해줌
           - 장점 : 중개자 없이 메모리에 바로 접근 → 가장 빠름
        1. 메모리 맵
           - 공유메모리 처럼 메모리를 공유 but 파일을 메모리에 매핑시켜 공유
             - 공유 매개체 = 파일 + 메모리
           - ex. 대용량 데이터 공유시 사용
        1. 메일슬롯, 메일박스
           - 단방향, 브로드캐스팅(by UDP, 소켓)
           - 주소기반이라 통신범위 제한 X
        1. 소켓
        - 네트워크 소켓 통신을 통한 데이터 공유
          - 클라-서버가 소켓을 통해 통신하는 구조
        - ex. 원격 프로세스 통신에 사용
    - PCB란 무엇이고, 어떤 정보가 저장되는지?
      > 프로세스 제어블록(PCB)
      - 프로세스에 대한 정보가 저장되는 곳
        - 운영체제는 프로세스 관리를 위해, 프로세스의 생성과 동시에 고유한 PCB를 생성
        - 프로세스가 전환되면 진행하던 작업을 저장하고 CPU를 반환해야 함
          - 작업 진행 상황을 PCB에 저장해두고, CPU를 재할당받으면 종료된 부분부터 작업 수행
      - PCB 에 저장되는 정보
        - PID : 프로세스 식별번호
        - 프로세스 상태 : new, ready, running, waiting, terminated 등
        - PC(프로그램 카운터) : 다음에 실행할 명령어의 주소
        - CPU 레지스터
        - CPU 스케쥴링 정보 : 우선순위, 스케줄 큐 포인터...
        - 메모리 관리 정보 : 페이지 테이블, 세그먼트 테이블...
        - 입출력 상태 정보 : 프로세스에 할당된 입출력 장치들, 열린 파일 목록
        - 어카운팅 정보 : 사용된 CPU 시간, 시간제한, 계정번호...
    - 스레드란?
      > 프로세스 내 하나의 실행 흐름
      - 프로세스 내에서 Stack만 따로 할당받고 Code, Data, Heap 영역은 공유
    - 프로세스와 스레드의 차이점?
      - 프로세스 → 운영체제로부터 자원을 할당받아서 실행
      - 스레드 → 프로세스로부터 자원을 할당받아 실행, 프로세스 내 하나의 실행 흐름
      ***
      - 한 프로세스 내에서 여러 스레드 생성 가능
        - 각 스레드는 개별 스택을 갖고, 프로세스 전역 메모리 공간을 공유해 프로그램을 실행
      - 프로세스는 code, data, heap, stack영역을 독립적으로 가짐
      - 스레드는 자신을 포함하는 프로세스의 code, data, heap을 다른 스레드들과 공유하고, stack만 개별적으로 가짐
    - 멀티 프로세스, 멀티 쓰레드 차이점
      - **멀티프로세스**
        - 한 프로그램을 여러 프로세스로 나눠서 처리
        - 장점
          - 한 프로세스가 죽어도, 다른 프로세스는 계속 실행 됨
            - 프로세스 중 하나에 문제가 생겨도 다른 프로세스에 영향을 주지 않아, 작업속도가 느려지는 손해정도는 생기지만 정지되거나 하는 문제는 발생하지 않는다.
          - 여러 프로세스가 처리되어야 할 때 동일한 데이터를 사용하고, 이러한 데이터를 하나의 디스크에 두고 모든 CPU가 공유하면 비용 저렴
        - 단점 : Context Switching 자주 발생, 비용 큼
          - Context Switching 과정에서 캐시 메모리 초기화 등 무거운 작업이 진행되고 시간이 소모되는 등 오버헤드가 발생한다
        ***
        **멀티스레드**
        - 한 프로세스를 여러 스레드로 나눠서 처리
        - 장점
          - 프로세스의 자원 할당을 위한 시스템콜 적음
          - 간단한 통신 방법으로 프로그램 응답시간 단축
            - IPC보다 스레드 간 통신 비용이 적음 → 작업들 간 부담 감소
            - 스택영역을 제외한 메모리 영역을 공유하기에 통신 비용이 적다.
              - 힙 영역을 공유하므로 데이터를 주고 받을 수 있다.
          - Context Switching 오버헤드가 줄어듦, 운영체제 부담이 덜함
        - 단점
          - 자원 공유 → 동기화 문제가 발생할 수 있다. (병목현상, 데드락 등)
            - 동기화에 신경써야 함!
              - 주의 깊은 설계가 필요, 디버깅이 어렵다.
                - 불필요 부분까지 동기화하면, 대기시간으로 인해 성능저하
          - 한 스레드에 문제가 생기면 전체 프로세스에 영향
          - 단일 프로세스 시스템의 경우 효과를 기대하기 어렵다.
    - 멀티 프로세스, 멀티 쓰레드가 각각 쓰일 수 있는 상황?
      - **멀티 프로세스**
      - 브라우저의 각 탭(크롬)
        - 한 프로세스가 비정상적으로 종료되더라도 다른 프로세스가 영향을 받지 않음
        - 자원을 공유할 필요가 없음
      - **멀티 스레드**
        - 워드 프로세스 등 응용 소프트웨어
        - 여러가지 기능, 메모리 공유
    - 크롬탭은 프로세스? 쓰레드?
      - 프로세스
        - 탭마다 PID를 가지고 있고, 랜더링 정보 등 데이터를 따로 관리
        - 장점 : 한 탭에 오류가 생겨도 모든 Tab에 영향을 끼치지 않음
        - 단점 : 메모리를 많이 잡아먹음
    - Context Switching?
      - CPU는 여러 프로세스들의 작업을 돌아가며 처리하는데, 이 때 CPU 레지스터 정보가 변경되는 것
        - 프로세스가 대기할 때 보관했던 상태(Context)를, 동작할 때 복구하는 작업
    - 스택을 스레드마다 독립적으로 할당하는 이유?
      - 스택 : 함수 인자, 되돌아갈 주소값, 함수 내 변수 등을 저장하는 메모리 공간
      - 스택 메모리 공간이 독립적 = 독립적인 함수 호출 가능 = 독립적인 실행 흐름 추가 가능
        ⇒ 독립적인 실행 흐름을 추가하기 위한 최소 조건으로 독립된 스택을 할당!
    - PC Register 를 스레드마다 독립적으로 할당하는 이유?
      - PC 값 = 스레드가 명령어를 어디까지 수행했는지를 나타냄
      - 스레드는 CPU를 할당받았다가 스케줄러에 의해 다시 선점당함
        → 명령어가 연속적으로 수행되지 못함
        → 어디까지 수행했는지 기억해둬야 이어서 실행 가능 - 따라서 PC 레지스터를 독립적으로 할당
    - 스레드간 통신 방법?
      - Heap 같은 공유되는 메모리에 쓰기, 읽기 할 수 있음
        - 프로세스 자원 변경하면 서로 변경 결과 즉시 확인 가능
    - 프로세스/스레드 동기화문제 해결방법?
      - 유저모드 동기화
        - 임계 영역 기반 동기화
        - 인터락 함수 기반 동기화
      - 커널모드 동기화
        - 세마포어, 뮤텍스
        - 이벤트 (실행순서 동기화)
          - 특정사건 발생을 다른 스레드에 알림
        - 모니터
    - 뮤텍스, 세마포어의 차이점은?
      - 뮤텍스 < 세마포어 (포함관계)
      - 동기화 대상 개수가 가장 큰 차이
        - 뮤텍스는 하나뿐, 세마포어는 하나 이상
        - 뮤텍스는 1개, 세마포어는 여러개의 쓰레드가 동시 접근 가능
      - 뮤텍스는 소유 가능, 세마포어는 소유 불가능
        - 세마포어는 세마포어 카운트로 판단하기 때문
    - 사용자 수준 스레드 vs 커널 수준 스레드 차이점?
      - **사용자 수준 스레드**
        - 장점 : context switching X → 오버헤드가 적음
          - 스레드 전환 시 커널 스케줄러 호출할 필요 X
        - 단점 : 스레드가 커널로 진입하는 순간, 프로세스 내 나머지 스레드들도 전부 정지됨
          - 커널이 스레드의 존재를 알지 못하기 때문
      - **커널 수준 스레드**
        - 장점 : 커널 스레드를 쓰면 멀티프로세서를 활용할 수 있어 효율적
          - 사용자 스레드는 CPU가 아무리 많아도 커널 모드의 스케줄이 되지 않아서, 각 CPU에 효율적으로 스레드 배당 불가
        - 단점 : context switching 발생 (사용자 모드 & 커널 모드 전환)

1.  임계영역, 교착상태(deadlock)

    - 임계영역(Critical Section)이란?
      > 여러 쓰레드가 동시에 접근할 위험이 있는 코드블럭
    - 임계영역 해결 조건?
      - **상호배제** : 한 쓰레드만 진입 가능
      - **진행** : 임계구역에 접근하는 쓰레드 결정은 유한시간 내에 이루어져야함
      - **유한대기**: 유한시간 내에 임계구역에 진입할 수 있어야함
    - 임계영역 문제 해결책
      - **Semaphores(세마포어)**
        - 임계구역 문제를 해결하기 위한 동기화 도구 (소프트웨어)
        - **종류**
          1. 카운팅 세마포
             - 접근 가능한 프로세스 수를 count하는 방식
               - 프로세스가 접근하면 count 감소, 벗어나면 count 증가시키고, 0되면 block하는 식으로!
          2. MUTEX (이진 세마포어)
             - 이름 그대로 0, 1 값만 가능 (count = 1인 세마포어)
          - **단점** - 바쁜 대기 - 초기에는 임계구역에 진입해야하는 프로세스가 진입 코드를 반복 실행했음
            → block된 이후 프로세스는 list(큐)에 넣어두고 임계구역에서 프로세스가 나오면서 깨우는 방식으로 해결 - Deadlock (교착상태) - 한 프로세스는 임계구역 진입을 기다리고, 임계구역에서 실행중인 프로세스는 대기 중인 프로세스가 실행되어야 빠져나올 수 있는 상황
      - **Lock**
        - 하드웨어 기반 해결책
        - 임계구역에 진입하는 프로세스는 Lock을 획득, 빠져나올 때는 Lock을 방출해서 동시 접근을 막음
      - **모니터**
        - lock기능을 제공하는 동기화 도구
          - 데이터에 모니터를 결합하면 동시에 접근하지 못하게 됨
          - 세마포어보다 고수준의 개념이라 더 요즘은 많이 사용
        - 상호배제큐, 조건동기큐로 구성
          - 상호배제큐 → 한 프로세스만 접근하게함
          - 조건동기큐 → 공유자원을 사용중인 프로세스가 wait()하면, 조건동기큐에 넣을 수 있고, nofity()로 깨울 수 있음
        - 공유자원에 접근 키 획득, 해제를 모두 처리
          - 세마포어는 직접 키 해제, 접근 처리가 필요
    - 교착상태란 무엇이고, 네가지 조건은?

      > 여러 프로세스나 스레드가, 서로 원하는 자원이 서로에게 할당되어있어 무한 대기상태에 빠져 다음 처리를 못하는 상태

      - **4가지 조건**
      - 넷 중 하나라도 만족하지 않으면 교착상태 발생 X

        1. 상호배제 : 한 자원에 동시 접근 불가
        2. 점유&대기 : 자원을 가진 상태(점유)에서 또 다른 자원을 기다림(대기)
        3. 비선점 : 자원 사용이 끝날 때까지 뺏을 수 없음
        4. 순환대기 : 프로세스는 자원을 순환적으로 가짐 (점유 대기 + 비선점)

        - 프로세스는 자원을 가진 상태에서 또다른 자원을 기다리는데, 자원은 사용이 끝날 때까지 뺏을 수 없음

    - 교착상태 해결방법
      1. 예방
         - 교착상태의 필요조건을 부정해 교착상태가 발생하지 않도록 미리 예방하는 방법
         - 네가지 필요조건 중 하나 부정
           - 상호배제 부정: 자원을 공유 (불가능한 경우가 많음)
           - 점유대기 부정: 자원을 갖고있는데 다른거 기다리지 않게함 (자원 활용률 저하)
           - 비선점 부정: 자원을 뻇을 수 있게함 (불가능한 경우가 많음)
           - 순환대기 부정: 자원에 번호 부여해서 순서대로 요청하게함 (자원 활용률 저하)
      2. 회피
         - 교착상태 원인 = 자원 할당을 잘못한 것으로 가정
           - 할당을 안정/불안정 할당으로 구분
         - 단점 : 자원 요청때마다 상태 파악 필요 → overhead
         - 은행원 알고리즘 (할당후에도 안전상태면 할당)
      3. 탐지 & 복구
         - 교착상태를 허용하되, 주기적으로 검사, 발생시 복구
           - 탐지
             - 자원할당 그래프로 탐지
           - 복구
             - 프로세스 일부 강제종료 → 희생자 선택 필요
             - 자원 선점(뺏어다 다른프로세스 주기) → 희생자 선택, 기아 상태 고려
         - 단점 : 자원 요청시 탐지 알고리즘 실행 → 오버헤드
      4. 무시
         - 교착상태가 발생하지 않는다고 가정하고 무시
           - 발생하면 직접 프로세스를 죽이거나, 재부팅
           - 교착상태 잘 발생하지 않으면 이게 더 효율적일수도
    - 은행원 알고리즘이란?
      - 모든 고객의 요구가 충족되도록, 현금을 나눠주는데서 유리
      - 자원 보유 상태, max needs(프로세스의 최대 자원요청), current needs(현재 빌린 자원수)
        - 이 정보들 기반으로, 자원을 할당해도 안정 상태가 되는지 파악
          - 안정이면 자원 할당, 불안정이면 대기시킴
    - 경합조건(Race Condition)이란?
      > 여러 프로세스/스레드가 공통자원에 동시에 접근할 때, 접근 순서에 따라 실행 결과가 달라질 수 있는 상태
      - 자료의 일관성을 해칠 수 있음
      - 피하는 방법
        - 상호배제
        - 임계구역
          - 여러 스레드가 동시에 접근해서는 안되는 임계구역 설정 (+ 세마포어, 뮤텍스로 임계구역 제어)

1.  스케줄러
    - 스케줄러?
      > 프로세스 상태를 조정하는 역할 담당
    - 선점, 비선점 스케줄링
      - **선점 (= 쫓아내기 가능)**
        - 우선순위 높은 프로세스가 생성되면, 실행중이던 프로세스는 밀려남 (time slice 끝나면)
          - 스케줄러가 프로세스 실행에 직접적으로 관여
            - CPU 사용권 강제 회수
        - ex. I/O, 이벤트 대기
          - 실행 중인 프로세스가 입출력이나 이벤트를 처리해야 할 때, 다 끝날 때까지 대기 상태로 만드는 것
      - **비선점 (= 쫓아내기 불가능)**
        - 우선순위 높은 프로세스가 생성되어도, 실행중이던 프로세스는 밀어내지 X
          - 프로세스 종료, I/O .. 등 발생까지 실행 보장
          - 실행중이던게 Ready로 가면 그때 실행
        - ex. 인터럽트, 스케줄러 디스패치
          - 인터럽트 : 예외, 입출력, 이벤트 등 발생시
          - 스케줄러 디스패치 : 준비 상태인 프로세스 중 하나를 실행시키는 것
    - 스케줄러의 종류
      > 실행 빈도에 따라 구분
      - **단기 스케줄러**
        > CPU 스케줄러 (일반적으로 말하는 스케줄러!)
        - 준비 상태의 작업 중 실행 할 프로세스를 선택해 CPU를 할당
          - CPU-메모리 스케줄링 담당
          - 프로세스들간의 우선순위를 정하기 위해 동작
      - **중기 스케줄러**
        > 교체 (Swapping)
        - Trashing : 가상메모리 체제에서, 프로세스가 무리하게 적재되면 시스템이 멈추는 현상 발생
        - 스와핑(Swapping)
          - 일부 프로세스를 메모리 → 디스크로 보내고(swap-out), 메모리에 여유가 생기면 다시 적재(swap-in)
      - **장기 스케줄러**
        > 작업 스케줄러
        - 어떤 프로그램을 HDD → 메모리로 적재할지 결정
          - 메모리-디스크 사이 스케줄링 담당
            - 디스크 등에 작업들을 저장해 놓고, 필요할때마다 작업을 Ready Queue에서 꺼내 메모리에 적재
    - 스케줄링 알고리즘
      - 비선점 스케줄링
        1. FCFS (First Come First Served)
           - 큐에 도착한 순서대로 CPU 할당
             - 실행 시간 긴게 앞에 있으면, 평균 대기시간 길어짐
        2. SJF (Shortest Job First)
           - 실행시간이 짧은것부터 할당
             - FCFS에 비해 평균 대기시간 감소
             - 짧은 작업에 유리
        3. HRN (Highest Response-ratio Next)
           - 대기시간, 실행시간 고려해서 점유 불평등 문제 보완(SJF의 단점 보완)
           - 우선순위 = (대기시간 + 실행시간) / 실행시간
      - 선점 스케줄링
        1. Round Robin
           - 한 프로세스가 할당 받은 시간(time slice)동안 작업하다가, 시간이 지나면 큐의 맨 뒤로가서 자기 차례를 기다리는 방식
             - time slice가 크면 FCFS랑 마찬가지 (하나가 거의 다 끝나고 그다음이 실행됨)
             - time slice가 작으면 Context Switching이 자주발생 → 오버헤드 증가
        2. 우선순위 스케줄링
           - 우선순위 순서대로 처리
           - 우선 순위가 낮으면 무한정 기다릴 수 있음 (Starvation)
             - Aging으로 해결 가능
        3. 다단계 큐 스케줄링
           - 우선순위에 따라 여러개의 큐를 사용
           - 장점 : 우선순위, 작업형태 고려해서 큐마다 Time slice 다르게 설정 가능
             - 전면 프로세스는 반응속도 빠르도록 작게, 후면 프로세스는 크게
               → 사용자 상호작용이 많은 전면은 반응속도 빠르게
           - 단점 : 우선순위가 낮은 프로세스에 불리
             - 우선순위가 높은 큐의 프로세스 작업이 끝나야 하위도 작업 가능
             - 우선순위가 높은 큐는 Time slice 작게, 낮은 큐는 크게 할당
               → 우선순위가 낮은 큐도 실행 가능
        4. 다단계 피드백 큐 스케줄링
           - 프로세스 실행 후에 원래큐가 아니라 우선순위 하나 낮은 큐로 들어감
             - CPU를 할당받아 실행될 때마다 프로세스 우선순위를 하나씩 낮춤
               → 우선순위가 낮은 프로세스의 실행기회를 확대하기 위해
           - 짧은 작업에 유리, I/O위주(인터럽트가 잦은) 작업에 우선권을 줌
1.  메모리 관리 전략
    - Paging, Segmentation
      - **페이징**
        - 프로세스를 작게 같은 크기로 나눠서 관리
          - 프로세스는 Page, 메모리는 Frame 단위로 분리 (크기 같음)
          - 장점 : 외부 단편화 문제 해결
            - 페이지는 순서에 상관없이 물리 메모리의 프레임에 매핑되어 저장되어 외부 단편화 문제 해결 가능
              - MMU가 논리주소 → 물리주소 변환 담당 (동적 재배치 by 페이지 테이블)
            - 외부 단편화 = 메모리의 남는 공간(hole)이 분산됨, 합치면 공간 충분한데 분산되어서 프로세스 할당 불가
          - 단점 : 내부 단편화 - 프로세스 크기가 페이지 크기의 배수가 아니면, 마지막 페이지는 한 프레임 다 쓰지 못해 메모리 낭비 발생 (외부단편화보다는 덜 낭비)
      - **세그먼테이션**
        - 논리적 내용을 기반으로, 세그먼트 단위로 나눔
          - 미리 분할X, 메모리 사용 시점에 할당됨
          - 단점 : 외부 단편화
            - 결국 크기가 동일하지 않을 수 있어서 다시 외부단편화 문제 발생
          - 장점 : 내부 단편화 해결, 공유/보안 효율적
            - 공유 : 여러 프로세스들이 공유하는 부분이 생겼을 때, 논리적으로 나누어진 해당 부분만 공유하면 되기 때문에 (ex. Code 영역)
    - 외부단편화, 내부단편화?
      - 단편화 : 프로세스들이 메모리에 load, 제거되는 작업이 반복되어 메모리에 hole들이 생기는 것
      - 외부단편화 : hole이 분산되어 메모리에 낭비하는 부분이 생기는 것
      - 내부단편화 : 프로세스가 사용하는 메모리 공간 내에 낭비되는 부분이 생기는 것
        - ex. 한 프레임 다 쓰지 못하는 것
    - 가상 메모리란?
      > 프로세스 중 당장 실행에 필요한 부분만 메인메모리에 올려두고, 나머지는 보조장치에 두는 기법
      - 물리 메모리보다 큰 프로세스를 실행하기 위해 사용
      - 프로세스가 필요한 메모리 공간의 일부를 가상메모리에서 제공
    - Demand Paging (요구 페이징)
      > 필요한 페이지만 메모리에 올려서 시간, 메모리 낭비 줄이는 기법
      - 프로그램 실행 시작 시에 필요한 부분만 메모리에 load
      - 프로세스 내 각 페이지들은 pager에 의해 관리됨
    - 페이지 교체 알고리즘
      - **페이지 교체**
        - CPU가 실행에 필요한 페이지를 요청 → 메모리에 없으면 page fault(페이지 부재)가 발생 → 보조저장장치에서 찾아옴
          - 페이지 부재 = CPU가 필요한 페이지가 메모리에 없는 경우 (페이지테이블 valid = 0)
          - 물리 메모리가 모두 사용중이면 페이지 교체 or 프로세스 강제종료 필요
      - **알고리즘**
        - FIFO : 메모리가 할당된 순서대로 페이지를 교체
        - OPT : 가장 오랫동안 사용하지 않을 '것'같은 페이지 교체 (최적 교체) → 실현 가능성 희박
        - LRU : 최근에 가장 오래 사용하지 않은 페이지를 교체
        - LFU : 사용 빈도가 가장 적은 페이지를 교체
        - NUR : 최근에 사용하지 않은 페이지를 교체
1.  캐시의 지역성
    - 캐시의 지역성 원리
      - 캐시 = 속도가 빠른 장치와 느린 장치간 속도차로 인한 병목 현상을 줄이기 위한 메모리
      - CPU가 어떤 데이터를 필요로 할지 예측이 필요한데, 이 때 적중율(Hit rate)을 높이기 위해 지역성(Locality)의 원리를 사용
    - **지역성**
      - 전제조건 : 프로그램은 모든 코드, 데이터에 균등하게 접근하지 않는다
      - 시간 지역성 : 최근에 접근한 주소에 다시 접근할 가능성이 높다
      - 공간 지역성 : 최근 접근한 주소 근처에 다시 접근할 가능성이 높다
1.  가비지 컬렉션
    - 가비지 컬렉션이란 무엇이고, js는 어떤 알고리즘을 사용하나요?
      - 가비지 = 정리되지 않은 메모리, 유효하지 않은 메모리 주소
      - 가비지 컬렉터
        - 가비지를 다른 용도로 사용할 수 있도록 '메모리 해제'를 시켜줌
      - mark-and-sweep 알고리즘
        - mark : 루트부터 시작해서, 루트가 참조하는 모든 객체를 재귀적으로 방문하고 마크
          - root
            - 전역 변수
            - 현재 함수의 지역 변수, 매개변수
            - 스코프 체인에서 사용되는 변수, 매개변수
        - sweep : 마크되지 않은 데이터들은 메모리에서 삭제
    - 최적화 기법?
      - 세대별 수집
        - 생성되지 얼마 안된 객체 → 더 집중적으로 감시
          - 대부분 생성이후 빠르게 쓸모가 없어지기 때문
        - 일정시간 살아남은 객체는 '오래된 객체' → 덜 감시
      - CPU가 쉬고 있을 때만 GC 실행시킴
1.  멀티 프로세싱, 멀티 프로그래밍의 차이점?
    - 멀티 프로세싱 = 여러개의 CPU로 작업을 병렬로 실행
    - 멀티 프로그래밍 = 여러 프로그램이 주기억장치에 함께 있도록 한 방식
1.  CPU vs GPU
    - CPU
      - 컴퓨터 두뇌, 각종 제어 처리를 위한 부분이 많음
      - 직렬 처리 (순차 작업)
    - GPU
      - 그래픽 등 특화된 연산을 빠른 속도로 처리하기 위해 단순한 ALU를 여러개 갖고 있는 구조
        - GPU는 단독으로는 아무것도 처리할 수 없음! CPU가 제어해야함
      - 병렬적인 작업에 특화
1.  동기, 비동기식의 차이점과 장단점?
    - **동기**
      - 요청에 대한 응답이 오면 다음 요청을 하는 방식
      - 장점 : 구성 단순, 순서대로 실행 가능 (좀 더 의도대로?)
      - 단점 : 여러 일을 동시에 수행하는 멀티태스킹은 불가
    - **비동기**
      - 응답을 기다리지 않고 다음 동작을 진행하는 방식
      - 장점 : 동시에 여러 일을 수행
      - 단점 : 일정 시간당 요청량이 많아지면 부하 발생 가능 → 오히려 추가처리 필요해질수도
